{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alwa\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "import pickle as cPickle\n",
    "import collections\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import operator\n",
    "f = open(os.path.join('dataset', 'tips.data'), 'rb')\n",
    "data = cPickle.load(f)\n",
    "\n",
    "\n",
    "train_s=['Train_10','Train_20','Train_50','Train_100']\n",
    "test_s=['Test_10','Test_20','Test_50','Test_100']\n",
    "test_poiT_s=['True_10','True_20','True_50','True_100']\n",
    "\n",
    "stoplist = set('for a an of the and to in is are it you I me'.split())\n",
    "\n",
    "def evaluate_score():\n",
    "    #evaluate the score for each user\n",
    "    a=[]\n",
    "    for i in data[user][test_poiT]:\n",
    "        count=len(data[user][test])\n",
    "        for poi,score_sim in sorted_POI_dict: \n",
    "            \n",
    "            if poi ==i :\n",
    "                if (count > (len(data[user][test])-len(data[user][test_poiT]))):\n",
    "                    a.append(len(data[user][test]))\n",
    "                    \n",
    "                else:\n",
    "                    a.append(count)\n",
    "                                     \n",
    "            count = count - 1\n",
    "    return sum(a)/len(data[user][test_poiT])*(1.0/len(data[user][test]))\n",
    "\n",
    "def Collection_words(_user,dd,_poi):\n",
    "    texts=[[''.join(e for e in word if e.isalpha()) for word in document.lower().split() if word not in stoplist] \n",
    "            for document in data[_user][dd][_poi]]\n",
    "    #remove ''space word\n",
    "    texts = [[word for word in text if word not in ''] for text in texts]\n",
    "    aList=[]\n",
    "    for document in texts:\n",
    "        for word in document:\n",
    "            aList.append(word)\n",
    "    return aList        \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)], [(14, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)], [(8, 1), (20, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1)], [(0, 1), (9, 1), (14, 1), (27, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 2), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 2), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1)], [(61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1)], [(9, 1), (18, 1), (52, 2), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 2)], [(50, 1), (55, 1), (93, 1), (94, 2), (95, 2), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1)], [(95, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1)], [(114, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1)], [(111, 1), (126, 1), (127, 1), (128, 1), (129, 1)], [(15, 1), (19, 1), (86, 1), (130, 1), (131, 1), (132, 1)], [(127, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1)], [(9, 1), (14, 2), (35, 1), (37, 1), (41, 1), (47, 1), (52, 1), (55, 1), (81, 1), (86, 1), (111, 1), (125, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1)], [(6, 1), (121, 1), (142, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 1)], [(21, 1), (54, 1), (85, 1), (141, 1), (151, 1), (163, 1), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1)], [(178, 1), (179, 1), (180, 1), (181, 1)], [(20, 1), (106, 1), (107, 1), (110, 1), (125, 1), (148, 1), (167, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1)], [(50, 1), (86, 1), (95, 1), (130, 1), (135, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1)], [(19, 1), (52, 1), (84, 1), (172, 1), (188, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1)], [(14, 1), (15, 1), (25, 1), (86, 1), (178, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 1)], [(15, 1), (55, 1), (125, 1), (142, 1), (146, 1), (206, 1), (207, 1), (208, 1), (209, 1), (210, 1), (211, 1), (212, 1), (213, 1), (214, 1), (215, 1)], [(14, 1), (15, 1), (27, 1), (81, 1), (105, 1), (111, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1)], [(34, 1), (55, 1), (106, 1), (148, 1), (211, 1), (234, 1), (235, 1), (236, 1), (237, 1), (238, 1), (239, 1)], [(20, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 1), (245, 1)], [(14, 1), (18, 1), (35, 1), (52, 1), (200, 1), (211, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1)]]\n"
     ]
    }
   ],
   "source": [
    "output = {}\n",
    "for train,test,test_poiT in zip(train_s,test_s,test_poiT_s):\n",
    "    usersocre_dict = collections.defaultdict(list)\n",
    "    for user in data.keys():\n",
    "        user_texts=[]\n",
    "        #######collect future word from each comment to construct dictionary and corpus\n",
    "        for poi in data[user][train].keys():\n",
    "            train_list= Collection_words(user,train,poi)\n",
    "            user_texts.append(train_list)\n",
    "        \n",
    "        dictionary = corpora.Dictionary(user_texts)\n",
    "        corpus = [dictionary.doc2bow(text) for text in user_texts]\n",
    "        #######\n",
    "        \n",
    "        ###rank the test sample by the similarity with train sample\n",
    "        POI_dict = collections.defaultdict(list)\n",
    "        for poi in data[user][test].keys():\n",
    "            test_list=Collection_words(user,test,poi)\n",
    "            new_vec = dictionary.doc2bow(test_list)   \n",
    "            lsi = models.LsiModel(corpus, id2word=dictionary)\n",
    "            vec_lsi = lsi[new_vec] # convert the query to LSI space\n",
    "            index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "            sims = index[vec_lsi] # perform a similarity query against the corpus\n",
    "            POI_dict[poi]=sum(sims)\n",
    "    \n",
    "        sorted_POI_dict = sorted(POI_dict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        ###\n",
    "        \n",
    "\n",
    "        usersocre_dict[user] = evaluate_score() \n",
    "#     break\n",
    "    output[train]=usersocre_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train_10': defaultdict(list,\n",
       "             {72: 0.5,\n",
       "              102: 0.2,\n",
       "              104: 0.4,\n",
       "              334: 1.0,\n",
       "              429: 0.7000000000000001,\n",
       "              616: 0.6000000000000001,\n",
       "              953: 0.1,\n",
       "              1317: 1.0,\n",
       "              1319: 0.6000000000000001,\n",
       "              1342: 1.0,\n",
       "              2448: 0.9,\n",
       "              4787: 0.6000000000000001,\n",
       "              5009: 0.2,\n",
       "              5183: 0.6000000000000001,\n",
       "              5503: 0.7000000000000001,\n",
       "              7599: 0.6000000000000001,\n",
       "              8051: 0.6000000000000001,\n",
       "              8388: 0.4,\n",
       "              8466: 0.2,\n",
       "              9962: 0.30000000000000004,\n",
       "              11075: 0.30000000000000004,\n",
       "              11466: 0.9,\n",
       "              13095: 0.5,\n",
       "              13999: 1.0,\n",
       "              15416: 0.1,\n",
       "              16255: 0.1,\n",
       "              16602: 0.30000000000000004,\n",
       "              17435: 0.4,\n",
       "              19335: 0.1,\n",
       "              19732: 0.4,\n",
       "              20537: 0.6000000000000001,\n",
       "              21380: 0.6000000000000001,\n",
       "              22056: 0.8,\n",
       "              23420: 0.1,\n",
       "              24436: 1.0,\n",
       "              24772: 0.1,\n",
       "              24873: 1.0,\n",
       "              24915: 0.6000000000000001,\n",
       "              25094: 0.9,\n",
       "              25807: 0.6000000000000001,\n",
       "              27297: 0.2,\n",
       "              27404: 0.5,\n",
       "              29831: 0.30000000000000004,\n",
       "              30502: 0.4,\n",
       "              33560: 0.30000000000000004,\n",
       "              33575: 0.8,\n",
       "              40518: 0.8,\n",
       "              40642: 0.30000000000000004,\n",
       "              42214: 0.4,\n",
       "              43127: 1.0,\n",
       "              43905: 0.8,\n",
       "              47683: 1.0,\n",
       "              48682: 0.4,\n",
       "              49206: 0.6000000000000001,\n",
       "              49805: 1.0,\n",
       "              50152: 1.0,\n",
       "              50489: 0.9,\n",
       "              50730: 1.0,\n",
       "              60211: 0.5,\n",
       "              63386: 0.6000000000000001,\n",
       "              64130: 0.2,\n",
       "              65107: 0.8,\n",
       "              66227: 0.30000000000000004,\n",
       "              78275: 0.30000000000000004,\n",
       "              82569: 0.8,\n",
       "              86519: 0.5,\n",
       "              89566: 0.8,\n",
       "              141794: 1.0,\n",
       "              143431: 0.8,\n",
       "              154689: 0.1,\n",
       "              193062: 0.7000000000000001,\n",
       "              196154: 1.0,\n",
       "              204517: 0.1,\n",
       "              211609: 0.1,\n",
       "              215619: 0.2,\n",
       "              257034: 0.2}),\n",
       " 'Train_100': defaultdict(list,\n",
       "             {72: 0.378,\n",
       "              102: 0.616,\n",
       "              104: 0.252,\n",
       "              334: 0.8940000000000001,\n",
       "              429: 0.396,\n",
       "              616: 0.616,\n",
       "              953: 0.38,\n",
       "              1317: 0.7440000000000001,\n",
       "              1319: 0.41600000000000004,\n",
       "              1342: 0.8059999999999999,\n",
       "              2448: 0.38200000000000006,\n",
       "              4787: 0.326,\n",
       "              5009: 0.172,\n",
       "              5183: 0.258,\n",
       "              5503: 0.79,\n",
       "              7599: 0.3,\n",
       "              8051: 0.314,\n",
       "              8388: 0.21,\n",
       "              8466: 0.7340000000000001,\n",
       "              9962: 0.308,\n",
       "              11075: 0.46,\n",
       "              11466: 0.188,\n",
       "              13095: 0.128,\n",
       "              13999: 0.76,\n",
       "              15416: 0.48600000000000004,\n",
       "              16255: 0.306,\n",
       "              16602: 0.68,\n",
       "              17435: 0.39,\n",
       "              19335: 0.544,\n",
       "              19732: 0.18600000000000003,\n",
       "              20537: 0.35200000000000004,\n",
       "              21380: 0.386,\n",
       "              22056: 0.672,\n",
       "              23420: 0.38,\n",
       "              24436: 0.40399999999999997,\n",
       "              24772: 0.19,\n",
       "              24873: 0.9259999999999999,\n",
       "              24915: 0.12400000000000001,\n",
       "              25094: 0.794,\n",
       "              25807: 0.72,\n",
       "              27297: 0.47000000000000003,\n",
       "              27404: 0.396,\n",
       "              29831: 0.31,\n",
       "              30502: 0.5579999999999999,\n",
       "              33560: 0.086,\n",
       "              33575: 0.36200000000000004,\n",
       "              40518: 0.456,\n",
       "              40642: 0.4,\n",
       "              42214: 0.21600000000000003,\n",
       "              43127: 0.294,\n",
       "              43905: 0.35600000000000004,\n",
       "              47683: 0.504,\n",
       "              48682: 0.488,\n",
       "              49206: 0.618,\n",
       "              49805: 0.378,\n",
       "              50152: 0.6659999999999999,\n",
       "              50489: 0.9620000000000001,\n",
       "              50730: 0.47000000000000003,\n",
       "              60211: 0.308,\n",
       "              63386: 0.252,\n",
       "              64130: 0.378,\n",
       "              65107: 0.688,\n",
       "              66227: 0.546,\n",
       "              78275: 0.368,\n",
       "              82569: 0.7859999999999999,\n",
       "              86519: 0.28,\n",
       "              89566: 0.9500000000000001,\n",
       "              141794: 0.758,\n",
       "              143431: 0.608,\n",
       "              154689: 0.392,\n",
       "              193062: 0.8320000000000001,\n",
       "              196154: 0.8440000000000001,\n",
       "              204517: 0.48600000000000004,\n",
       "              211609: 0.532,\n",
       "              215619: 0.41000000000000003,\n",
       "              257034: 0.386}),\n",
       " 'Train_20': defaultdict(list,\n",
       "             {72: 0.45,\n",
       "              102: 0.525,\n",
       "              104: 0.47500000000000003,\n",
       "              334: 0.47500000000000003,\n",
       "              429: 0.275,\n",
       "              616: 0.225,\n",
       "              953: 0.15000000000000002,\n",
       "              1317: 0.125,\n",
       "              1319: 0.4,\n",
       "              1342: 1.0,\n",
       "              2448: 0.625,\n",
       "              4787: 0.225,\n",
       "              5009: 0.675,\n",
       "              5183: 0.125,\n",
       "              5503: 0.07500000000000001,\n",
       "              7599: 0.9,\n",
       "              8051: 0.4,\n",
       "              8388: 0.07500000000000001,\n",
       "              8466: 0.275,\n",
       "              9962: 0.47500000000000003,\n",
       "              11075: 0.30000000000000004,\n",
       "              11466: 0.30000000000000004,\n",
       "              13095: 0.07500000000000001,\n",
       "              13999: 1.0,\n",
       "              15416: 0.47500000000000003,\n",
       "              16255: 0.30000000000000004,\n",
       "              16602: 0.875,\n",
       "              17435: 0.375,\n",
       "              19335: 0.65,\n",
       "              19732: 0.42500000000000004,\n",
       "              20537: 0.1,\n",
       "              21380: 0.5750000000000001,\n",
       "              22056: 0.75,\n",
       "              23420: 0.45,\n",
       "              24436: 0.17500000000000002,\n",
       "              24772: 0.47500000000000003,\n",
       "              24873: 0.9,\n",
       "              24915: 0.1,\n",
       "              25094: 0.9500000000000001,\n",
       "              25807: 0.47500000000000003,\n",
       "              27297: 0.07500000000000001,\n",
       "              27404: 0.6000000000000001,\n",
       "              29831: 0.125,\n",
       "              30502: 0.7250000000000001,\n",
       "              33560: 0.47500000000000003,\n",
       "              33575: 0.1,\n",
       "              40518: 0.2,\n",
       "              40642: 0.125,\n",
       "              42214: 0.17500000000000002,\n",
       "              43127: 0.30000000000000004,\n",
       "              43905: 0.925,\n",
       "              47683: 0.45,\n",
       "              48682: 0.625,\n",
       "              49206: 0.6000000000000001,\n",
       "              49805: 0.375,\n",
       "              50152: 0.8250000000000001,\n",
       "              50489: 0.9,\n",
       "              50730: 0.325,\n",
       "              60211: 0.675,\n",
       "              63386: 0.275,\n",
       "              64130: 0.7000000000000001,\n",
       "              65107: 0.8250000000000001,\n",
       "              66227: 0.42500000000000004,\n",
       "              78275: 0.6000000000000001,\n",
       "              82569: 1.0,\n",
       "              86519: 0.8250000000000001,\n",
       "              89566: 1.0,\n",
       "              141794: 0.8500000000000001,\n",
       "              143431: 0.07500000000000001,\n",
       "              154689: 0.125,\n",
       "              193062: 0.875,\n",
       "              196154: 0.675,\n",
       "              204517: 0.47500000000000003,\n",
       "              211609: 0.65,\n",
       "              215619: 0.25,\n",
       "              257034: 0.625}),\n",
       " 'Train_50': defaultdict(list,\n",
       "             {72: 0.912,\n",
       "              102: 0.436,\n",
       "              104: 0.23600000000000002,\n",
       "              334: 0.716,\n",
       "              429: 0.62,\n",
       "              616: 0.444,\n",
       "              953: 0.168,\n",
       "              1317: 0.568,\n",
       "              1319: 0.5,\n",
       "              1342: 0.47600000000000003,\n",
       "              2448: 0.544,\n",
       "              4787: 0.568,\n",
       "              5009: 0.43200000000000005,\n",
       "              5183: 0.228,\n",
       "              5503: 0.588,\n",
       "              7599: 0.36,\n",
       "              8051: 0.38,\n",
       "              8388: 0.184,\n",
       "              8466: 0.588,\n",
       "              9962: 0.49600000000000005,\n",
       "              11075: 0.436,\n",
       "              11466: 0.32,\n",
       "              13095: 0.364,\n",
       "              13999: 0.5,\n",
       "              15416: 0.48,\n",
       "              16255: 0.44799999999999995,\n",
       "              16602: 0.368,\n",
       "              17435: 0.324,\n",
       "              19335: 0.508,\n",
       "              19732: 0.484,\n",
       "              20537: 0.228,\n",
       "              21380: 0.408,\n",
       "              22056: 0.41600000000000004,\n",
       "              23420: 0.264,\n",
       "              24436: 0.46399999999999997,\n",
       "              24772: 0.12400000000000001,\n",
       "              24873: 1.0,\n",
       "              24915: 0.23600000000000002,\n",
       "              25094: 1.0,\n",
       "              25807: 0.9159999999999999,\n",
       "              27297: 0.376,\n",
       "              27404: 0.46399999999999997,\n",
       "              29831: 0.344,\n",
       "              30502: 0.43200000000000005,\n",
       "              33560: 0.43200000000000005,\n",
       "              33575: 0.168,\n",
       "              40518: 0.46399999999999997,\n",
       "              40642: 0.508,\n",
       "              42214: 0.204,\n",
       "              43127: 0.6,\n",
       "              43905: 0.508,\n",
       "              47683: 0.556,\n",
       "              48682: 0.41600000000000004,\n",
       "              49206: 0.488,\n",
       "              49805: 0.136,\n",
       "              50152: 0.608,\n",
       "              50489: 0.876,\n",
       "              50730: 0.24800000000000003,\n",
       "              60211: 0.44,\n",
       "              63386: 0.264,\n",
       "              64130: 0.256,\n",
       "              65107: 0.584,\n",
       "              66227: 0.44799999999999995,\n",
       "              78275: 0.608,\n",
       "              82569: 0.624,\n",
       "              86519: 0.596,\n",
       "              89566: 0.948,\n",
       "              141794: 0.976,\n",
       "              143431: 0.47600000000000003,\n",
       "              154689: 0.312,\n",
       "              193062: 0.272,\n",
       "              196154: 0.488,\n",
       "              204517: 0.5920000000000001,\n",
       "              211609: 0.78,\n",
       "              215619: 0.384,\n",
       "              257034: 0.408})}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "score={}\n",
    "for train in train_s:\n",
    "    score[train]=sum(output[train].values())/len(output[train])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train_10': 0.5565789473684213,\n",
       " 'Train_100': 0.4758157894736842,\n",
       " 'Train_20': 0.48059210526315804,\n",
       " 'Train_50': 0.47389473684210526}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "for train,test,test_poiT in zip(train_s,test_s,test_poiT_s):\n",
    "    usersocre_dict = collections.defaultdict(list)\n",
    "    for user in data.keys():\n",
    "        user_texts=[]\n",
    "        #######collect future word from each comment to construct dictionary and corpus\n",
    "        for poi in data[user][train].keys():\n",
    "            train_list= Collection_words(user,train,poi)\n",
    "            user_texts.append(train_list)\n",
    "        \n",
    "        dictionary = corpora.Dictionary(user_texts)\n",
    "        corpus = [dictionary.doc2bow(text) for text in user_texts]\n",
    "        #######\n",
    "#         break\n",
    "        word2vec = models.Word2Vec(user_texts, size=100, window=5, min_count=1, workers=4)\n",
    "        user_w2v = np.zeros(100)\n",
    "        for sentence in user_texts:\n",
    "            tmp = np.zeros(100)\n",
    "            for word in sentence:\n",
    "#                 print(word, sentence)\n",
    "                tmp += np.array(word2vec[word])\n",
    "            tmp /= len(sentence)\n",
    "            user_w2v += tmp\n",
    "        user_w2v /= len(user_texts)\n",
    "#         print(user_w2v)\n",
    "        ###rank the test sample by the similarity with train sample\n",
    "        POI_dict = collections.defaultdict(list)\n",
    "        for poi in data[user][test].keys():\n",
    "            test_list=Collection_words(user,test,poi)\n",
    "#             new_vec = dictionary.doc2bow(test_list)   \n",
    "            poi_sentence = np.zeros(100)\n",
    "            for word in test_list:\n",
    "                if word in word2vec:\n",
    "                    poi_sentence += np.array(word2vec[word])\n",
    "#             print(poi_sentence)\n",
    "            POI_dict[poi]= cosine_similarity(poi_sentence.reshape(1,-1), user_w2v.reshape(1,-1))\n",
    "        \n",
    "        sorted_POI_dict = sorted(POI_dict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        ###\n",
    "        \n",
    "    \n",
    "        usersocre_dict[user] = evaluate_score() \n",
    "    \n",
    "    output[train]=usersocre_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train_10': 0.5657894736842105,\n",
       " 'Train_100': 0.5134473684210527,\n",
       " 'Train_20': 0.4960526315789473,\n",
       " 'Train_50': 0.505842105263158}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score={}\n",
    "for train in train_s:\n",
    "    score[train]=sum(output[train].values())/len(output[train])\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
